{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import uuid\n",
    "import gc\n",
    "import random as rn\n",
    "\n",
    "from logging import getLogger, Formatter, StreamHandler, FileHandler, INFO\n",
    "from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from contextlib import contextmanager\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "\n",
    "import pywt\n",
    "import h5py\n",
    "import vaex\n",
    "#vaex.multithreading.thread_count_default = 8\n",
    "import vaex.ml\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import einops as eo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import scipy.stats as stats\n",
    "import cufflinks as cf\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "keras = tf.keras\n",
    "layers = keras.layers\n",
    "\n",
    "from IPython.display import display\n",
    "from dask_ml.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from dask.distributed import Client\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "from dask_utils import (swapaxes_shuffle, shuffle_blocks_together,\n",
    "                        stack_interleave_flatten, chunk_generator)\n",
    "\n",
    "#cluster = LocalCluster(n_workers=1, threads_per_worker=1)\n",
    "#c = Client(cluster)\n",
    "\n",
    "# set plotly in notebook mode\n",
    "init_notebook_mode(connected=True)\n",
    "# likewise cufflinks for offline use\n",
    "cf.go_offline()\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "%matplotlib inline\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load radio signal burst data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses the \"DeepSig RADIOML 2018.01A\" open dataset provided at:\n",
    "\n",
    "https://www.deepsig.ai/datasets\n",
    "\n",
    "The dataset includes both synthetic simulated channel effects and over-the-air recordings of 24 digital and analog modulation types which has been heavily validated.\n",
    "\n",
    "This dataset was used for [Over-the-air deep learning based radio signal classification](https://arxiv.org/pdf/1712.04578.pdf) published 2017 in IEEE Journal of Selected Topics in Signal Processing, which provides additional details and description of the dataset.\n",
    "\n",
    "Data are stored in hdf5 format as complex floating point values, with 2 million examples, each 1024 samples long.\n",
    "\n",
    "These  include  a  number  of  high  ordermodulations (QAM256 and APSK256), which are used in thereal world in very high-SNR low-fading channel environments such as on [impulsive satellite links](https://www.researchgate.net/publication/280972230_Transmission_parameters_optimization_and_receiver_architectures_for_DVB-S2X_systems) (e.g. DVB-S2X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "X_shf_path = '../data/shf.hdf5' # precalculated shuffled sequences\n",
    "\n",
    "# named types of radio signal for each set of samples in order\n",
    "classes = [\n",
    "    '32PSK','16APSK','32QAM','FM','GMSK','32APSK','OQPSK','8ASK',\n",
    "    'BPSK','8PSK','AM-SSB-SC','4ASK','16PSK','64APSK','128QAM','128APSK',\n",
    "    'AM-DSB-SC','AM-SSB-WC','64QAM','QPSK','256QAM','AM-DSB-WC','OOK','16QAM'\n",
    "]\n",
    "classes = pd.Series(classes).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the arrays for each 1024-sample-long example burst into dask arrays.\n",
    "\n",
    "- X represents the two-dimensional (I, Q) values for every sample in the burst\n",
    "- Y represents the one-hot encoded category (corresponding to the signal modulation types above) for each burst\n",
    "- Z represents the signal-to-noise-ratio (SNR) for each burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(data_path, \"r\")\n",
    "print(\"datasets found: \", list(f.keys()))\n",
    "for k in f.keys():\n",
    "    print(k, \"has shape:\", f[k].shape)\n",
    "# read arrays with Dask\n",
    "X = da.from_array(f['X'], chunks=('auto', 1024, 2)) # samples * timesteps * features (I, Q)\n",
    "Y = da.from_array(f['Y'], chunks=(X.chunks[0], -1)) # samples * one-hot-encoded class\n",
    "Z = da.from_array(f['Z'], chunks=(X.chunks[0], -1)) # samples * SNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the samples are arranged by classification/SNR across the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf_snr = pd.DataFrame(\n",
    "    data=np.vstack(\n",
    "        [\n",
    "            da.argmax(Y, axis=1).compute(),\n",
    "            Z.compute().flatten()\n",
    "        ]\n",
    "    ).T,\n",
    "    columns=['label', 'SNR']\n",
    ")\n",
    "# visualise SNR monotonically increasing for each classification across dataset\n",
    "axs = df_clf_snr.groupby('label')['SNR'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut on SNR > min value (paper reports <10% accuracy for the high negative SNR samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_snr = 8\n",
    "df_clf_snr_filtered = df_clf_snr.query(f'SNR >= {min_snr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 49152 burst samples per class with SNR > 8\n",
    "# 4096 samples per SNR per label\n",
    "print(df_clf_snr_filtered['SNR'].unique().shape[0], \"unique SNR values\")\n",
    "df_clf_snr_filtered.reset_index().groupby(['label', 'SNR']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out samples with SNR in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X[df_clf_snr_filtered.index.values]\n",
    "Y_filtered = Y[df_clf_snr_filtered.index.values]\n",
    "Z_filtered = Z[df_clf_snr_filtered.index.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab one signal sample from each class for visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_samples = (\n",
    "    df_clf_snr_filtered.reset_index(drop=True).reset_index().groupby(\n",
    "        ['label']\n",
    "    ).first()\n",
    ")\n",
    "first_sample_indices = first_samples['index'].values\n",
    "\n",
    "X_samples = X_filtered[first_sample_indices].compute()\n",
    "Y_samples = Y_filtered[first_sample_indices].compute()\n",
    "Z_samples = Z_filtered[first_sample_indices].compute()\n",
    "\n",
    "# 24 samples total of sequences of shape 1024 (samples) * 2 (compoents)\n",
    "print(X_samples.shape)\n",
    "print(Y_samples.shape)\n",
    "print(Z_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the paper: \n",
    "\n",
    "\"We  use  asecond  B210  (with  a  separate  free-running  LO)  to  receive these transmissions in the lab, over a relatively benign indoor wireless channel on the 900MHz ISM band.\"\n",
    "\n",
    "I'll assume this means the sampling frequency is 900MHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 9.0e8\n",
    "N_samples = X_samples.shape[1]\n",
    "T = 1.0 / sampling_rate\n",
    "t = np.linspace(0.0, N_samples*T, N_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise I/Q values over time in 3D for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict which data to plot (crowded 3D plots are messy)\n",
    "n_classes_to_visualise = 3\n",
    "# undersample by a factor of show_nth_sample for clarity\n",
    "show_nth_sample = 16\n",
    "# plot and superimpose each example sequence\n",
    "traces = [\n",
    "    go.Scatter3d(\n",
    "        name=classes[first_samples.index][i],\n",
    "        x=X_samples[i, ::show_nth_sample, 0],\n",
    "        y=t,\n",
    "        z=X_samples[i, ::show_nth_sample, 1],\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            colorscale='Viridis',\n",
    "        ),\n",
    "        line=dict(\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    "    for i in range(X_samples[:n_classes_to_visualise].shape[0])\n",
    "]\n",
    "fig = go.Figure(data=traces)\n",
    "# set figure layout\n",
    "fig.update_layout(\n",
    "    title=\"I/Q plot over sample sequences of various signal types\",\n",
    "    autosize=False,\n",
    "    scene=dict(\n",
    "        xaxis_title='I',\n",
    "        yaxis_title='time',\n",
    "        zaxis_title='Q',\n",
    "        aspectratio = dict( x=1, y=3., z=1 ),\n",
    "        aspectmode = 'manual'\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in-phase component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nth_sample = 1\n",
    "n_classes_to_visualise = 4\n",
    "\n",
    "traces = [\n",
    "    go.Scatter(\n",
    "        name=classes[first_samples.index][i],\n",
    "        x=t,\n",
    "        y=X_samples[i, ::show_nth_sample, 0],\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            colorscale='Viridis',\n",
    "        ),\n",
    "        line=dict(\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    "    for i in range(X_samples[:n_classes_to_visualise].shape[0])\n",
    "]\n",
    "fig = go.Figure(data=traces)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frequency domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/tutorial/fft.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_to_visualise = 4\n",
    "show_nth_freq_component = 1\n",
    "traces = []\n",
    "\n",
    "for ix in range(n_classes_to_visualise):\n",
    "    # magnitude of fourier components\n",
    "    yf = fft(X_samples[ix, :, 0] + 1j*X_samples[ix, :, 1])\n",
    "    yf = 1/N_samples * np.abs(fftshift(yf))\n",
    "    # frequency range\n",
    "    xf = np.linspace(0.0, 1.0/(1.0*T), N_samples)\n",
    "    xf = fftfreq(N_samples, T)\n",
    "    xf = fftshift(xf)\n",
    "    plot_data = go.Scatter(\n",
    "        name=classes[first_samples.index][ix],\n",
    "        x=xf[::show_nth_freq_component],\n",
    "        y=yf[::show_nth_freq_component],\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            colorscale='Viridis',\n",
    "        ),\n",
    "        line=dict(\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    "    traces.append(plot_data)\n",
    "fig = go.Figure(data=traces)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify swapaxes shuffle is reordering samples as anticipated, traversing permutations of label/SNR first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=np.vstack(\n",
    "        [\n",
    "            da.argmax(swapaxes_shuffle(Y_filtered), axis=1).compute(),\n",
    "            da.squeeze(swapaxes_shuffle(Z_filtered)).compute()\n",
    "        ]\n",
    "    ).T,\n",
    "    columns=['label', 'SNR']\n",
    ").head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform the swapaxes shuffling on each array to intersperse examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the burst samples themselves, go through an intermediate hdf5 file to avoid dask scheduler\n",
    "# having a fit and blowing up RAM...\n",
    "if not Path(X_shf_path).exists():\n",
    "    swapaxes_shuffle(X_filtered).to_hdf5('shf.hdf5', '/X')\n",
    "f = h5py.File(X_shf_path, \"r\")\n",
    "print(\"datasets found: \", list(f.keys()))\n",
    "for k in f.keys():\n",
    "    print(k, \"has shape:\", f[k].shape)\n",
    "# read arrays with Dask\n",
    "X_filtered = da.from_array(f['X'], chunks=('auto', -1, -1)) # samples * timesteps * features (I, Q)\n",
    "\n",
    "# do classifications and SNRs regularly\n",
    "Y_filtered = swapaxes_shuffle(Y_filtered).rechunk(X_filtered.chunks[0], -1)\n",
    "Z_filtered = swapaxes_shuffle(Z_filtered).rechunk(X_filtered.chunks[0], -1)\n",
    "\n",
    "print(X_filtered.numblocks[0], \"blocks of size\", X_filtered.chunksize[0])\n",
    "assert X_filtered.numblocks[0] == Y_filtered.numblocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sum = X_filtered.sum(axis=1).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 53 train / 10 validation / 10 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = X_filtered.blocks[:53], X_filtered.blocks[53:63], X_filtered.blocks[63:]\n",
    "Y_train, Y_val, Y_test = Y_filtered.blocks[:53], Y_filtered.blocks[53:63], Y_filtered.blocks[63:]\n",
    "Z_train, Z_val, Z_test = Z_filtered.blocks[:53], Z_filtered.blocks[53:63], Z_filtered.blocks[63:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_pipeline():\n",
    "    \"\"\"\n",
    "    Input data training pipeline. Simple Z-score rescaling.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`sklearn.pipeline.Pipeline`\n",
    "        A pipeline for preprocessing input signal samples. Currently\n",
    "        just simple scaling.\n",
    "    \"\"\"\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "    ]\n",
    "    return Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform preprocessing before shuffling to save computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply z-score scaling to samples (~2m)\n",
    "X_pipeline = make_X_pipeline()\n",
    "X_train = X_pipeline.fit_transform(X_train)\n",
    "X_val = X_pipeline.transform(X_val)\n",
    "X_test = X_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle and prepare batch generation from delayed arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fancy_batch_generator(X:da.Array,\n",
    "                          Y:da.Array,\n",
    "                          batch_size:int,\n",
    "                          augger=None,\n",
    "                          client=None,\n",
    "                          seed:int=42,\n",
    "                          shuffle_blocks_every_epoch:bool=False,\n",
    "                          shuffle_within_blocks:bool=True,\n",
    "                          float32=True):\n",
    "    \"\"\"\n",
    "    Generates batches of image/mask pairs from dask arrays with augmentations.\n",
    "    Proceeds chunk by chunk through the dask array, generating smaller numpy\n",
    "    arrays of the appropriate `batch_size` from these as it goes along. Applies\n",
    "    image and mask augmentations to each of these.\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgs: :obj:`dask.array.Array`\n",
    "        A dask array of images distributed along axis 0\n",
    "    masks: :obj:`dask.array.Array`\n",
    "        A dask array of masks distributed along axis 0\n",
    "    batch_size: int\n",
    "        The batch size of the yielded arrays\n",
    "    augger: callable, optional\n",
    "        A function applying augmentations to batches (X, Y)\n",
    "    client: :obj:`distributed.Client`, optional\n",
    "        Dask distributed client for mapping parallel augmentation jobs\n",
    "    pyramid_y: bool, optional\n",
    "        Instead of returning masks, return a list of masks at \n",
    "        [8th, 4th, half, native] resolution. for attention pyramid unet.\n",
    "    seed: int\n",
    "        Random seed\n",
    "    shuffle: bool\n",
    "        Flags whether to shuffle within the chunks.\n",
    "    Yields\n",
    "    ------\n",
    "    tuple of :obj:`numpy.ndarray`:\n",
    "        (images, masks) with augmentations applied and shape (batch_size, h, w, c)\n",
    "    \"\"\"\n",
    "    # instantiate distributed scheduler if not passed\n",
    "    if client is None:\n",
    "        close_client_after = True\n",
    "        client = Client() \n",
    "    # track nsamples\n",
    "    n_samples = X.shape[0]\n",
    "    # seed numpy\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    # keep yielding\n",
    "    epochs = 0\n",
    "    # -- loop over whole dask array\n",
    "    while True:\n",
    "        # get chunk generator for larger-than-memory image and mask arrays\n",
    "        chunk_gen =  chunk_generator([X, Y], shuffle_blocks=shuffle_blocks_every_epoch)\n",
    "        # for each image/mask chunk in RAM, do a chunk-epoch worth of\n",
    "        # data-augmented batch generation\n",
    "        # -- loop over chunks: these are now numpy arrays\n",
    "        for i, (X_chunk, Y_chunk) in enumerate(chunk_gen):\n",
    "            log.debug(f\"Dask Chunk: {i+1}\\n\")\n",
    "            # get indices of chunk\n",
    "            n_samples_chunk = X_chunk.shape[0]\n",
    "            n_batches_chunk = int(n_samples_chunk/batch_size)\n",
    "            index = np.arange(0, n_samples_chunk)\n",
    "            # optionally shuffle inplace\n",
    "            if shuffle_within_blocks:\n",
    "                np.random.shuffle(index)\n",
    "            start_point, batches = 0, 0 # track processed samples and batches\n",
    "            # -- loop over batches in chunk\n",
    "            while True:\n",
    "                log.debug(f\"Batch: {batches}\")\n",
    "                inds = index[start_point:start_point+batch_size]\n",
    "                Xb, Yb = X_chunk[inds], Y_chunk[inds]\n",
    "                # augment this batch\n",
    "                if augger is not None:\n",
    "                    Xb, Yb = augment_all(Xb, Yb, augger, client)\n",
    "                if float32:\n",
    "                    Xb = Xb.astype('float32')\n",
    "                    Yb = Yb.astype('float32')\n",
    "                # try to clean up autocreated client if tf stops iteration\n",
    "                try:\n",
    "                    yield Xb, Yb\n",
    "                except StopIteration:\n",
    "                    if close_client_after:\n",
    "                        client.close()\n",
    "                    raise\n",
    "                start_point += batch_size\n",
    "                batches += 1\n",
    "                # stop if we reach the end of the chunk\n",
    "                if batches >= n_batches_chunk:\n",
    "                    break\n",
    "        # -- epoch end\n",
    "        epochs += 1\n",
    "        log.debug(f\"Finished generating epoch: {epochs}!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test block generator\n",
    "for Xb_train, Yb_train in chunk_generator([X_train, Y_train]):\n",
    "    assert Xb_train.shape[0] == Yb_train.shape[0]\n",
    "    break\n",
    "#print(\"should see most if not all classes in the first block with sufficient shuffling:\")\n",
    "#print(\"classes in first block: \", np.unique(np.argmax(Yb_train, axis=1)))\n",
    "# if not, increase \"repeats\" in synchronised pseudoshuffle. this incrases memory usage and computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batch generator\n",
    "for X_batch, Y_batch in fancy_batch_generator(X_train, Y_train, batch_size=64):\n",
    "    assert X_batch.shape[0] == Y_batch.shape[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveNet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask, attention_dropout=0., trainable=False):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    if trainable:\n",
    "        attention_weights = tf.nn.dropout(attention_weights, 1.0 - attention_dropout)\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 attention_dropout=0.1,\n",
    "                 trainable=True,\n",
    "                 name='MultiHeadAttention'):\n",
    "        \"\"\"\n",
    "        Adapted from Google's Transformer implementation at:\n",
    "            https://www.tensorflow.org/tutorials/text/transformer#masking\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.trainable = trainable\n",
    "        self.attention_dropout = attention_dropout\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask, trainable=self.trainable, attention_dropout=self.attention_dropout)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test SA layer\n",
    "#hidden_size = 2\n",
    "#batch_size = 8\n",
    "#X0_batch = X0[:batch_size]\n",
    "#sa = MultiHeadAttention(hidden_size, num_heads=1)\n",
    "#sa(X0_batch, X0_batch, X0_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(layers.Activation):\n",
    "    '''\n",
    "    Mish Activation Function.\n",
    "    .. math::\n",
    "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
    "    Shape:\n",
    "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "        - Output: Same shape as the input.\n",
    "    Examples:\n",
    "        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'Mish'\n",
    "\n",
    "\n",
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
    "\n",
    "get_custom_objects().update({'Mish': Mish(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveNetResidualConv1D(num_filters, kernel_size, stacked_layer):\n",
    "\n",
    "    def build_residual_block(l_input):\n",
    "        resid_input = l_input\n",
    "        for dilation_rate in [2**i for i in range(stacked_layer)]:\n",
    "            l_sigmoid_conv1d = layers.Conv1D(\n",
    "                num_filters, kernel_size, dilation_rate=dilation_rate,\n",
    "                padding='same', activation='sigmoid'\n",
    "            )(l_input)\n",
    "            l_tanh_conv1d = layers.Conv1D(\n",
    "                num_filters, kernel_size, dilation_rate=dilation_rate,\n",
    "                padding='same', activation='Mish'\n",
    "            )(l_input)\n",
    "            l_input = layers.Multiply()([l_sigmoid_conv1d, l_tanh_conv1d])\n",
    "            l_input = layers.Conv1D(num_filters, 1, padding='same')(l_input)\n",
    "            resid_input = layers.Add()([resid_input ,l_input])\n",
    "        return resid_input\n",
    "    return build_residual_block\n",
    "\n",
    "def WaveNetClassifier(shape_):\n",
    "    num_filters_ = 16\n",
    "    kernel_size_ = 3\n",
    "    stacked_layers_ = [12, 8, 4, 1]\n",
    "    LR = 0.0001\n",
    "    output_dim = 24\n",
    "    l_input = layers.Input(shape=(shape_))\n",
    "    x = layers.Conv1D(num_filters_, 1, padding='same')(l_input)\n",
    "    x = WaveNetResidualConv1D(num_filters_, kernel_size_, stacked_layers_[0])(x)\n",
    "    x = layers.Conv1D(num_filters_*2, 1, padding='same')(x)\n",
    "    x = WaveNetResidualConv1D(num_filters_*2, kernel_size_, stacked_layers_[1])(x)\n",
    "    x = layers.Conv1D(num_filters_*4, 1, padding='same')(x)\n",
    "    x = WaveNetResidualConv1D(num_filters_*4, kernel_size_, stacked_layers_[2])(x)\n",
    "    x = layers.Conv1D(num_filters_*8, 1, padding='same')(x)\n",
    "    x = WaveNetResidualConv1D(num_filters_*8, kernel_size_, stacked_layers_[3])(x)\n",
    "    # collapse sequences to output class vector\n",
    "    x = layers.Conv1D(output_dim, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Softmax()(x)\n",
    "    #x = layers.Dropout(0.1)(x)\n",
    "    #x = layers.Dense(20, activation=\"relu\")(x)\n",
    "    #x = layers.Dropout(0.1)(x)\n",
    "    #outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    #print(x.shape)\n",
    "    #l_output = layers.Dense(output_dim, activation='softmax')(x)\n",
    "    #print(l_input.shape, l_output.shape)\n",
    "    model = models.Model(inputs=[l_input], outputs=[outputs])\n",
    "    return model\n",
    "    opt = Adam(lr=LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveNetClassifier(X_train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "optimiser = 'adam'\n",
    "lr_init = 1e-4\n",
    "lr_reduce_factor = 0.5\n",
    "lr_reduce_patience = 2\n",
    "lr_min = 1e-6\n",
    "patience = 3\n",
    "\n",
    "train_steps = X_train.shape[0]//batch_size\n",
    "val_steps = X_val.shape[0]//batch_size\n",
    "batches_per_block = X_train.blocks[0].shape[0] / batch_size\n",
    "print(train_steps, \"train steps\")\n",
    "print(batches_per_block, \"batches per block\") # don't want to queue up more than one extra block for RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret optimizer\n",
    "if optimiser == 'sgd':\n",
    "    opt = tf.keras.optimizers.SGD(\n",
    "        learning_rate=lr_init, momentum=0.85, nesterov=False\n",
    "    )\n",
    "elif optimiser == 'adam':\n",
    "    opt = tf.keras.optimizers.Adam(\n",
    "        learning_rate=lr_init, beta_1=0.9, beta_2=0.999, amsgrad=False\n",
    "    ) # check out RADAM?\n",
    "else:\n",
    "    raise ValueError(f\"Optimiser {opt} not understood\")        \n",
    "opt = tfa.optimizers.SWA(opt)\n",
    "    \n",
    "# specify training directory to save weights and metrics for this loss_fn and data ID\n",
    "# within models_dir\n",
    "models_dir = Path('../models')\n",
    "project_name = Path(f'WaveNetClassifier_{uuid.uuid4()}')\n",
    "training_dir = Path(models_dir) / project_name\n",
    "training_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- callbacks\n",
    "\n",
    "# early stopping\n",
    "monitor = 'val_loss'\n",
    "callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(monitor, patience=patience)\n",
    "]\n",
    "\n",
    "# reduce the learning rate on plateaus\n",
    "callbacks.append(\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=monitor,\n",
    "                                         factor=lr_reduce_factor,\n",
    "                                         patience=lr_reduce_patience,\n",
    "                                         min_lr=lr_min)\n",
    ")\n",
    "\n",
    "# set up tensorboard to record metrics in a subdirectory\n",
    "tb_pth = training_dir / Path(\"metrics/\")\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=str(tb_pth),\n",
    "    update_freq=50\n",
    ")\n",
    "callbacks.append(tb_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up checkpoints in the training directory\n",
    "cp_fmt = 'cp-e{epoch:02d}-l{loss:.5f}-a{accuracy:.4f}'\n",
    "suffix = '-vl{val_loss:.5f}-va{val_accuracy:.4f}.ckpt'\n",
    "cp_fmt = cp_fmt + suffix\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(training_dir / Path(cp_fmt)), # saved_model\n",
    "    monitor=monitor,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly check\n",
    "X_train_blk_0 = X_train.blocks[0].compute()\n",
    "Y_train_blk_0 = Y_train.blocks[0].compute()\n",
    "Y_train_blk_0_cls = [classes[ix] for ix in np.argmax(Y_train_blk_0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nth_sample = 1\n",
    "n_classes_to_visualise = 24\n",
    "\n",
    "traces = [\n",
    "    go.Scatter(\n",
    "        name=Y_train_blk_0_cls[i],\n",
    "        x=t,\n",
    "        y=X_train_blk_0[i, ::show_nth_sample, 0],\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            colorscale='Viridis',\n",
    "        ),\n",
    "        line=dict(\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    "    for i in range(X_train_blk_0[:n_classes_to_visualise].shape[0])\n",
    "]\n",
    "fig = go.Figure(data=traces)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    fancy_batch_generator(X_train, Y_train, batch_size=batch_size, shuffle_blocks_every_epoch=False, shuffle_within_blocks=False),\n",
    "    steps_per_epoch=train_steps, # steps per epoch\n",
    "    epochs=epochs,\n",
    "    validation_data=fancy_batch_generator(X_val, Y_val, batch_size=batch_size),\n",
    "    validation_steps=val_steps,\n",
    "    max_queue_size=batches_per_block-1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1024 * 1024 * 16 / (1024^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c(X0_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spire] *",
   "language": "python",
   "name": "conda-env-spire-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
